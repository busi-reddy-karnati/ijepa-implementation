{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This example requires the following dependencies to be installed:\n",
    "pip install lightly[timm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightly[timm] in c:\\users\\busis\\anaconda3\\lib\\site-packages (1.5.13)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2024.8.30)\n",
      "Requirement already satisfied: hydra-core>=1.0.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (1.3.2)\n",
      "Requirement already satisfied: lightly-utils~=0.0.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (0.0.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2.32.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=4.44 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (4.66.4)\n",
      "Requirement already satisfied: torch in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (0.18.0+cu118)\n",
      "Requirement already satisfied: pydantic>=1.10.5 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2.5.3)\n",
      "Requirement already satisfied: pytorch-lightning>=1.0.4 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2.4.0)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (2.2.2)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (3.1.15)\n",
      "Requirement already satisfied: timm>=0.9.9 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly[timm]) (1.0.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from hydra-core>=1.0.0->lightly[timm]) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\busis\\anaconda3\\lib\\site-packages (from hydra-core>=1.0.0->lightly[timm]) (4.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\busis\\anaconda3\\lib\\site-packages (from hydra-core>=1.0.0->lightly[timm]) (23.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightly-utils~=0.0.0->lightly[timm]) (10.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from pydantic>=1.10.5->lightly[timm]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from pydantic>=1.10.5->lightly[timm]) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from pydantic>=1.10.5->lightly[timm]) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from pytorch-lightning>=1.0.4->lightly[timm]) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (2024.3.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from pytorch-lightning>=1.0.4->lightly[timm]) (1.4.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from pytorch-lightning>=1.0.4->lightly[timm]) (0.11.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from requests>=2.23.0->lightly[timm]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from requests>=2.23.0->lightly[timm]) (3.7)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\busis\\anaconda3\\lib\\site-packages (from timm>=0.9.9->lightly[timm]) (0.25.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\busis\\anaconda3\\lib\\site-packages (from timm>=0.9.9->lightly[timm]) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\busis\\anaconda3\\lib\\site-packages (from torch->lightly[timm]) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\busis\\anaconda3\\lib\\site-packages (from torch->lightly[timm]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\busis\\anaconda3\\lib\\site-packages (from torch->lightly[timm]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from torch->lightly[timm]) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from torch->lightly[timm]) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\busis\\anaconda3\\lib\\site-packages (from tqdm>=4.44->lightly[timm]) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (3.9.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\busis\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.0.4->lightly[timm]) (69.5.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\busis\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->lightly[timm]) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\busis\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->lightly[timm]) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from jinja2->torch->lightly[timm]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from sympy->torch->lightly[timm]) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\busis\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly[timm]) (1.9.3)\n",
      "Requirement already satisfied: typing in c:\\users\\busis\\anaconda3\\lib\\site-packages (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightly[timm]\n",
    "!pip install --upgrade typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.data.collate import IJEPAMaskCollator\n",
    "from lightly.models import utils\n",
    "from lightly.models.modules.ijepa import IJEPABackbone, IJEPAPredictor\n",
    "from lightly.transforms.ijepa_transform import IJEPATransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IJEPA(nn.Module):\n",
    "    def __init__(self, vit_encoder, vit_predictor, momentum_scheduler):\n",
    "        super().__init__()\n",
    "        self.encoder = IJEPABackbone.from_vit(vit_encoder)\n",
    "        self.predictor = IJEPAPredictor.from_vit_encoder(\n",
    "            vit_predictor.encoder,\n",
    "            (vit_predictor.image_size // vit_predictor.patch_size) ** 2,\n",
    "        )\n",
    "        self.target_encoder = copy.deepcopy(self.encoder)\n",
    "        self.momentum_scheduler = momentum_scheduler\n",
    "\n",
    "    def forward_target(self, imgs, masks_enc, masks_pred):\n",
    "        with torch.no_grad():\n",
    "            h = self.target_encoder(imgs)\n",
    "            h = F.layer_norm(h, (h.size(-1),))  # normalize over feature-dim\n",
    "            B = len(h)\n",
    "            # -- create targets (masked regions of h)\n",
    "            h = utils.apply_masks(h, masks_pred)\n",
    "            h = utils.repeat_interleave_batch(h, B, repeat=len(masks_enc))\n",
    "            return h\n",
    "\n",
    "    def forward_context(self, imgs, masks_enc, masks_pred):\n",
    "        z = self.encoder(imgs, masks_enc)\n",
    "        z = self.predictor(z, masks_enc, masks_pred)\n",
    "        return z\n",
    "\n",
    "    def forward(self, imgs, masks_enc, masks_pred):\n",
    "        z = self.forward_context(imgs, masks_enc, masks_pred)\n",
    "        h = self.forward_target(imgs, masks_enc, masks_pred)\n",
    "        return z, h\n",
    "\n",
    "    def update_target_encoder(\n",
    "        self,\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "            m = next(self.momentum_scheduler)\n",
    "            for param_q, param_k in zip(\n",
    "                self.encoder.parameters(), self.target_encoder.parameters()\n",
    "            ):\n",
    "                param_k.data.mul_(m).add_((1.0 - m) * param_q.detach().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = IJEPAMaskCollator(\n",
    "    input_size=(224, 224),\n",
    "    patch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = IJEPATransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "we ignore object detection annotations by setting target_transform to return 0\n",
    "or create a dataset from a folder containing images or videos:\n",
    "dataset = LightlyDataset(\"path/to/folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_transform(t):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.VOCDetection(\n",
    "    \"datasets/pascal_voc\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, collate_fn=collator, batch_size=10, persistent_workers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = (0.996, 1.0)\n",
    "ipe_scale = 1.0\n",
    "ipe = len(data_loader)\n",
    "num_epochs = 10\n",
    "momentum_scheduler = (\n",
    "    ema[0] + i * (ema[1] - ema[0]) / (ipe * num_epochs * ipe_scale)\n",
    "    for i in range(int(ipe * num_epochs * ipe_scale) + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_for_predictor = torchvision.models.vit_b_32(pretrained=False)\n",
    "vit_for_embedder = torchvision.models.vit_b_32(pretrained=False)\n",
    "model = IJEPA(vit_for_embedder, vit_for_predictor, momentum_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1.5e-4)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Training\")\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for udata, masks_enc, masks_pred in tqdm(data_loader):\n",
    "\n",
    "        def load_imgs():\n",
    "            # -- unsupervised imgs\n",
    "            imgs = udata[0].to(device, non_blocking=True)\n",
    "            masks_1 = [u.to(device, non_blocking=True) for u in masks_enc]\n",
    "            masks_2 = [u.to(device, non_blocking=True) for u in masks_pred]\n",
    "            return (imgs, masks_1, masks_2)\n",
    "\n",
    "        imgs, masks_enc, masks_pred = load_imgs()\n",
    "        z, h = model(imgs, masks_enc, masks_pred)\n",
    "        loss = criterion(z, h)\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        model.update_target_encoder()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
